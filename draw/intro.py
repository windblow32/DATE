import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.datasets import make_blobs
from sklearn import datasets
from matplotlib.colors import LogNorm
from scipy.stats import gaussian_kde
from sklearn.mixture import GaussianMixture
import matplotlib.gridspec as gridspec
from sklearn.neighbors import KernelDensity

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œé£æ ¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("white")

def generate_samples_global(X, n_samples=200):
    """æ•´ä½“ç”Ÿæˆæ•°æ® - å­¦ä¹ æ•´ä½“åˆ†å¸ƒ"""
    kde = gaussian_kde(X.T)
    generated_samples = kde.resample(n_samples).T
    return generated_samples

def generate_samples_partitioned(X, labels, n_samples=200):
    """åˆ’åˆ†åç”Ÿæˆæ•°æ® - æ¯ä¸ªåˆ†å¸ƒå•ç‹¬ç”Ÿæˆ"""
    generated_samples = []
    sample_weights = []
    
    # è®¡ç®—æ¯ä¸ªåˆ†å¸ƒçš„æ ·æœ¬æƒé‡
    for i in np.unique(labels):
        mask = labels == i
        sample_weights.append(np.sum(mask))
    
    sample_weights = np.array(sample_weights) / len(X)
    
    # ä¸ºæ¯ä¸ªåˆ†å¸ƒç”Ÿæˆæ ·æœ¬
    for i, weight in zip(np.unique(labels), sample_weights):
        mask = labels == i
        cluster_data = X[mask]
        n_cluster_samples = int(n_samples * weight)
        
        if len(cluster_data) > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®æ‹ŸåˆKDE
            kde = gaussian_kde(cluster_data.T)
            cluster_samples = kde.resample(n_cluster_samples).T
            generated_samples.append(cluster_samples)
    
    return np.vstack(generated_samples)


def plot_generation_comparison(X, labels, colors, names):
    """å¯¹æ¯”æ•´ä½“ç”Ÿæˆ vs åˆ’åˆ†ç”Ÿæˆçš„æ•ˆæœ"""
    # å®šä¹‰ä¸åŒå½¢çŠ¶çš„æ ‡è®°
    markers = ['o', 's', '^', 'D', '*', 'p', 'h', 'X']
    
    fig = plt.figure(figsize=(18, 11))
    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 1])
    
    # 1. åŸå§‹æ•°æ®åˆ†å¸ƒï¼ˆä¿æŒä¸å˜ï¼‰
    ax1 = plt.subplot(gs[0, 0])
    for i in np.unique(labels):
        mask = labels == i
        ax1.scatter(X[mask, 0], X[mask, 1], 
                   c=colors[int(i)], 
                   marker=markers[int(i) % len(markers)],
                   label=names[int(i)],
                   alpha=1, s=50, edgecolors='white', linewidth=0.5)
    # ax1.set_title('1. Original Data Distribution', fontsize=12, fontweight='bold')
    ax1.set_xlabel('Feature X')
    ax1.set_ylabel('Feature Y')
    # ax1.legend()
    # ax1.grid(True, alpha=0.3)
    
    # 2. æ•´ä½“ç”Ÿæˆçš„æ•°æ® - ä¿®æ”¹ï¼šåŒæ—¶æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œç”Ÿæˆæ•°æ®
    ax2 = plt.subplot(gs[0, 1])
    generated_global = generate_samples_global(X, n_samples=300)
    
    # å…ˆç»˜åˆ¶åŸå§‹æ•°æ®
    for i in np.unique(labels):
        mask = labels == i
        ax2.scatter(X[mask, 0], X[mask, 1], 
                   c=colors[int(i)], 
                   marker=markers[int(i) % len(markers)],
                   alpha=1, s=30, label=f'Original {names[int(i)]}')
    
    # å†ç»˜åˆ¶ç”Ÿæˆæ•°æ®
    # ax2.scatter(generated_global[:, 0], generated_global[:, 1], 
    #            c='pink', alpha=1, s=50,marker='*', label='Generated Data')
    darker_pink = (0.9, 0.4, 0.5)  # æ›´æ·±çš„ç²‰è‰²ï¼ŒRGBå€¼èŒƒå›´0-1
    ax2.scatter(generated_global[:, 0], generated_global[:, 1], 
            c=[darker_pink], alpha=1, s=120, marker='*', label='Generated Data',
            edgecolors='white', linewidth=0.5)

    # ax2.set_title('2. Global Generation\n(No Partition)', fontsize=12, fontweight='bold')
    ax2.set_xlabel('Feature X')
    ax2.set_ylabel('Feature Y')
    # ax2.legend()
    # ax2.grid(True, alpha=0.3)
    
    # 3. åˆ’åˆ†åç”Ÿæˆçš„æ•°æ® - ä¿®æ”¹ï¼šåŒæ—¶æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œç”Ÿæˆæ•°æ®
    ax3 = plt.subplot(gs[0, 2])
    generated_partitioned = generate_samples_partitioned(X, labels, n_samples=300)
    
    # ä¸ºç”Ÿæˆçš„æ ·æœ¬åˆ†é…é¢œè‰²å’Œå½¢çŠ¶
    from sklearn.neighbors import NearestNeighbors
    nbrs = NearestNeighbors(n_neighbors=1).fit(X)
    _, indices = nbrs.kneighbors(generated_partitioned)
    generated_labels = labels[indices.flatten()]
    
    # å…ˆç»˜åˆ¶åŸå§‹æ•°æ®
    for i in np.unique(labels):
        mask = labels == i
        ax3.scatter(X[mask, 0], X[mask, 1], 
                   c=colors[int(i)], 
                   marker=markers[int(i) % len(markers)],
                   alpha=1, s=30, label=f'Original {names[int(i)]}')
    
    # å†ç»˜åˆ¶ç”Ÿæˆæ•°æ®
    # for i in np.unique(labels):
    #     mask = generated_labels == i
    #     if np.sum(mask) > 0:
    #         ax3.scatter(generated_partitioned[mask, 0], generated_partitioned[mask, 1], 
    #                    c=colors[int(i)], 
    #                    marker=markers[int(i) % len(markers)],
    #                    alpha=1, s=50, 
    #                    label=f'Generated {names[int(i)]}')
    # åœ¨ç»˜åˆ¶ç”Ÿæˆæ•°æ®æ—¶ï¼Œä½¿ç”¨æ›´æ·±çš„é¢œè‰²
    # åœ¨ç»˜åˆ¶ç”Ÿæˆæ•°æ®æ—¶ï¼Œä¿®æ”¹è“è‰²ï¼ˆç¬¬äºŒä¸ªç±»åˆ«ï¼‰çš„åŠ æ·±ç¨‹åº¦
    for i in np.unique(labels):
        mask = generated_labels == i
        if np.sum(mask) > 0:
            # å°†é¢œè‰²è½¬æ¢ä¸ºRGBå¹¶åŠ æ·±
            color = plt.cm.colors.to_rgb(colors[int(i)])
            # å¦‚æœæ˜¯è“è‰²ï¼ˆç¬¬äºŒä¸ªç±»åˆ«ï¼‰ï¼Œä½¿ç”¨æ›´æ·±çš„é¢œè‰²
            if i == 1:  # å‡è®¾è“è‰²æ˜¯ç¬¬äºŒä¸ªç±»åˆ«
                darker_color = tuple([c * 0.4 for c in color])  # æ›´æ·±çš„è“è‰²
            else:
                darker_color = tuple([c * 0.6 for c in color])  # å…¶ä»–é¢œè‰²ä¿æŒåŸæ¥çš„åŠ æ·±ç¨‹åº¦
                
            ax3.scatter(generated_partitioned[mask, 0], generated_partitioned[mask, 1], 
                    c=[darker_color],
                    marker=markers[int(i) % len(markers)],
                    alpha=1, 
                    s=50, 
                    label=f'Generated {names[int(i)]}',
                    linewidth=0.5)
    
    # ax3.set_title('3. Partitioned Generation\n(Per Distribution)', fontsize=12, fontweight='bold')
    ax3.set_xlabel('Feature X')
    ax3.set_ylabel('Feature Y')
    # ax3.legend()
    # ax3.grid(True, alpha=0.3)

    from matplotlib.lines import Line2D
    legend_elements = []

    # æ·»åŠ åŸå§‹æ•°æ®å›¾ä¾‹
    for i in np.unique(labels):
        legend_elements.append(Line2D([0], [0], 
                            marker=markers[int(i) % len(markers)], 
                            color='w', 
                            label=f'Original {names[int(i)]}',
                            markerfacecolor=colors[int(i)],
                            markersize=10,
                            alpha=1))  # ä¿®æ”¹ä¸ºä¸é€æ˜

    # æ·»åŠ æ•´ä½“ç”Ÿæˆæ•°æ®å›¾ä¾‹
    darker_pink = (0.9, 0.4, 0.5)  # ä½¿ç”¨ä¸æ•£ç‚¹å›¾ç›¸åŒçš„æ·±ç²‰è‰²
    legend_elements.append(Line2D([0], [0], 
                            marker='*', 
                            color='w', 
                            label='Generated Data (Global)',
                            markerfacecolor=darker_pink,
                            markersize=12,
                            alpha=1))  # ä¿®æ”¹ä¸ºä¸é€æ˜

    # æ·»åŠ åˆ’åˆ†ç”Ÿæˆå›¾ä¾‹
    # åœ¨åˆ›å»ºå›¾ä¾‹æ—¶ï¼Œå¯¹è“è‰²ä½¿ç”¨ç›¸åŒçš„åŠ æ·±é€»è¾‘
    for i in np.unique(labels):
        # ä½¿ç”¨ä¸æ•£ç‚¹å›¾ç›¸åŒçš„é¢œè‰²åŠ æ·±é€»è¾‘
        color = plt.cm.colors.to_rgb(colors[int(i)])
        if i == 1:  # è“è‰²ç±»åˆ«
            darker_color = tuple([c * 0.3 for c in color])
        else:
            darker_color = tuple([c * 0.6 for c in color])
        
        legend_elements.append(Line2D([0], [0], 
                            marker=markers[int(i) % len(markers)], 
                            color='w', 
                            label=f'Generated {names[int(i)]}',
                            markerfacecolor=darker_color,
                            markersize=10,
                            alpha=1))

    # è°ƒæ•´å›¾å½¢å¸ƒå±€ï¼Œä¸ºé¡¶éƒ¨å›¾ä¾‹ç•™å‡ºç©ºé—´
    plt.subplots_adjust(top=0.85)

    # æ·»åŠ å›¾ä¾‹åœ¨å›¾å½¢é¡¶éƒ¨ä¸­å¤®
    fig.legend(handles=legend_elements, 
            loc='upper center', 
            bbox_to_anchor=(0.5, 1.0),
            ncol=3,
            frameon=True,
            fancybox=True,
            shadow=True,
            fontsize=18)

    plt.tight_layout()
    
    
    
    # # 4. å¯†åº¦å¯¹æ¯” - æ•´ä½“ç”Ÿæˆ
    # ax4 = plt.subplot(gs[1, 0])
    # # åŸå§‹æ•°æ®å¯†åº¦ï¼ˆä½é€æ˜åº¦ï¼‰
    # for i in np.unique(labels):
    #     mask = labels == i
    #     sns.kdeplot(x=X[mask, 0], y=X[mask, 1], 
    #                color=colors[int(i)], alpha=0.3, 
    #                label=f'Original {names[int(i)]}', ax=ax4)
    # # ç”Ÿæˆæ•°æ®å¯†åº¦ï¼ˆé«˜é€æ˜åº¦ï¼‰
    # sns.kdeplot(x=generated_global[:, 0], y=generated_global[:, 1], 
    #            color='red', alpha=0.8, label='Generated Data', ax=ax4)
    # ax4.set_title('4. Density: Global Generation', fontsize=12, fontweight='bold')
    # ax4.set_xlabel('Feature X')
    # ax4.set_ylabel('Feature Y')
    # ax4.legend()
    
    # # 5. å¯†åº¦å¯¹æ¯” - åˆ’åˆ†ç”Ÿæˆ
    # ax5 = plt.subplot(gs[1, 1])
    # # åŸå§‹æ•°æ®å¯†åº¦ï¼ˆä½é€æ˜åº¦ï¼‰
    # for i in np.unique(labels):
    #     mask = labels == i
    #     sns.kdeplot(x=X[mask, 0], y=X[mask, 1], 
    #                color=colors[int(i)], alpha=0.3, 
    #                label=f'Original {names[int(i)]}', ax=ax5)
    # # ç”Ÿæˆæ•°æ®å¯†åº¦ï¼ˆé«˜é€æ˜åº¦ï¼‰
    # for i in np.unique(labels):
    #     mask = generated_labels == i
    #     if np.sum(mask) > 0:
    #         sns.kdeplot(x=generated_partitioned[mask, 0], y=generated_partitioned[mask, 1], 
    #                    color=colors[int(i)], alpha=0.8, 
    #                    label=f'Generated {names[int(i)]}', ax=ax5)
    # ax5.set_title('5. Density: Partitioned Generation', fontsize=12, fontweight='bold')
    # ax5.set_xlabel('Feature X')
    # ax5.set_ylabel('Feature Y')
    # ax5.legend()
    
    # 6. è´¨é‡è¯„ä¼°
    ax6 = plt.subplot(gs[1, 2])
    ax6.axis('off')
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    def calculate_quality_metrics(original, generated, labels):
        metrics = {}
        
        # 1. åˆ†å¸ƒä¸€è‡´æ€§ï¼ˆWassersteinè·ç¦»ï¼‰
        from scipy.stats import wasserstein_distance
        metrics['wasserstein_x'] = wasserstein_distance(original[:, 0], generated[:, 0])
        metrics['wasserstein_y'] = wasserstein_distance(original[:, 1], generated[:, 1])
        
        # 2. è¦†ç›–åº¦ï¼ˆç”Ÿæˆçš„æ ·æœ¬åœ¨åŸå§‹åˆ†å¸ƒèŒƒå›´å†…çš„æ¯”ä¾‹ï¼‰
        x_range = (original[:, 0].min(), original[:, 0].max())
        y_range = (original[:, 1].min(), original[:, 1].max())
        
        x_in_range = np.sum((generated[:, 0] >= x_range[0]) & (generated[:, 0] <= x_range[1])) / len(generated)
        y_in_range = np.sum((generated[:, 1] >= y_range[0]) & (generated[:, 1] <= y_range[1])) / len(generated)
        metrics['coverage'] = (x_in_range + y_in_range) / 2
        
        # 3. èšç±»è´¨é‡ï¼ˆç”Ÿæˆçš„æ ·æœ¬æ˜¯å¦èƒ½å½¢æˆæ¸…æ™°çš„èšç±»ï¼‰
        from sklearn.metrics import silhouette_score
        if len(np.unique(labels)) > 1:
            # ä¸ºç”Ÿæˆæ•°æ®åˆ†é…æ ‡ç­¾
            nbrs = NearestNeighbors(n_neighbors=1).fit(original)
            _, indices = nbrs.kneighbors(generated)
            gen_labels = labels[indices.flatten()]
            metrics['silhouette'] = silhouette_score(generated, gen_labels)
        else:
            metrics['silhouette'] = 0
            
        return metrics
    
    metrics_global = calculate_quality_metrics(X, generated_global, labels)
    metrics_partitioned = calculate_quality_metrics(X, generated_partitioned, labels)
    
    comparison_text = f"""
    ğŸ” ç”Ÿæˆè´¨é‡å¯¹æ¯”åˆ†æï¼š
    
    ğŸ“Š æ•´ä½“ç”Ÿæˆ (Global):
    â€¢ Wassersteinè·ç¦»: {metrics_global['wasserstein_x']:.3f} (X), {metrics_global['wasserstein_y']:.3f} (Y)
    â€¢ è¦†ç›–åº¦: {metrics_global['coverage']*100:.1f}%
    â€¢ è½®å»“ç³»æ•°: {metrics_global['silhouette']:.3f}
    
    âš ï¸ é—®é¢˜:
    â€¢ æ•°æ®ä½ç½®æ•£ä¹±ï¼Œç¼ºä¹æ¸…æ™°ç»“æ„
    â€¢ æ— æ³•å­¦ä¹ å¤æ‚åˆ†å¸ƒçš„ç»†èŠ‚
    â€¢ ç”Ÿæˆæ•°æ®åˆ†å¸ƒæ¨¡ç³Š
    
    ğŸ“Š åˆ’åˆ†ç”Ÿæˆ (Partitioned):
    â€¢ Wassersteinè·ç¦»: {metrics_partitioned['wasserstein_x']:.3f} (X), {metrics_partitioned['wasserstein_y']:.3f} (Y)
    â€¢ è¦†ç›–åº¦: {metrics_partitioned['coverage']*100:.1f}%
    â€¢ è½®å»“ç³»æ•°: {metrics_partitioned['silhouette']:.3f}
    
    âœ… ä¼˜åŠ¿:
    â€¢ æ•°æ®ä½ç½®æ¸…æ™°ï¼Œä¿æŒåŸæœ‰ç»“æ„
    â€¢ å‡†ç¡®å­¦ä¹ æ¯ä¸ªåˆ†å¸ƒçš„ç‹¬ç‰¹æ¨¡å¼
    â€¢ ç”Ÿæˆæ•°æ®åˆ†å¸ƒæ˜ç¡®
    """
    
    ax6.text(0.05, 0.95, comparison_text, 
             transform=ax6.transAxes,
             fontsize=10, 
             verticalalignment='top',
             bbox=dict(boxstyle='round', 
                      facecolor='lightblue', 
                      alpha=0.8),
             linespacing=1.6)
    
    plt.tight_layout()
    plt.show()
    
    return generated_global, generated_partitioned

def plot_generation_details(X, labels, colors, names):
    """è¯¦ç»†å±•ç¤ºç”Ÿæˆè¿‡ç¨‹çš„ç»†èŠ‚"""
    # å®šä¹‰ä¸åŒå½¢çŠ¶çš„æ ‡è®°
    markers = ['o', 's', '^', 'D', '*', 'p', 'h', 'X']
    
    fig = plt.figure(figsize=(15, 10))
    gs = gridspec.GridSpec(2, 2, height_ratios=[1, 1])
    
    # ç”Ÿæˆæ•°æ®
    generated_global = generate_samples_global(X, n_samples=400)
    generated_partitioned = generate_samples_partitioned(X, labels, n_samples=400)
    
    # 1. æ•´ä½“ç”Ÿæˆçš„æ•£ä¹±é—®é¢˜ - ä¿®æ”¹ï¼šåŒæ—¶æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œç”Ÿæˆæ•°æ®
    ax1 = plt.subplot(gs[0, 0])
    
    # å…ˆç»˜åˆ¶åŸå§‹æ•°æ®
    for i in np.unique(labels):
        mask = labels == i
        ax1.scatter(X[mask, 0], X[mask, 1], 
                   c=colors[int(i)], 
                   marker=markers[int(i) % len(markers)],
                   alpha=1, s=20, label=f'Original {names[int(i)]}')
    
    # å†ç»˜åˆ¶ç”Ÿæˆæ•°æ®
    ax1.scatter(generated_global[:, 0], generated_global[:, 1], 
               c='red', alpha=1, s=40, label='Generated Data')
    
    ax1.set_title('Global Generation: Scattered Data', fontsize=12, fontweight='bold')
    ax1.set_xlabel('Feature X')
    ax1.set_ylabel('Feature Y')
    ax1.legend()
    # ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ è¯´æ˜
    ax1.text(0.05, 0.95, "âŒ Generated data scattered\nacross all clusters", 
             transform=ax1.transAxes, fontsize=10, color='red',
             bbox=dict(facecolor='white', alpha=0.8))
    
    # 2. åˆ’åˆ†ç”Ÿæˆçš„ç»“æ„ä¿æŒ - ä¿®æ”¹ï¼šåŒæ—¶æ˜¾ç¤ºåŸå§‹æ•°æ®å’Œç”Ÿæˆæ•°æ®
    ax2 = plt.subplot(gs[0, 1])
    
    # ä¸ºç”Ÿæˆçš„æ ·æœ¬åˆ†é…é¢œè‰²
    from sklearn.neighbors import NearestNeighbors
    nbrs = NearestNeighbors(n_neighbors=1).fit(X)
    _, indices = nbrs.kneighbors(generated_partitioned)
    generated_labels = labels[indices.flatten()]
    
    # å…ˆç»˜åˆ¶åŸå§‹æ•°æ®ï¼ˆä½é€æ˜åº¦ï¼‰
    for i in np.unique(labels):
        mask = labels == i
        ax2.scatter(X[mask, 0], X[mask, 1], 
                   c=colors[int(i)], 
                   marker=markers[int(i) % len(markers)],
                   alpha=0.2, s=20, label=f'Original {names[int(i)]}')
    
    # å†ç»˜åˆ¶ç”Ÿæˆæ•°æ®ï¼ˆé«˜é€æ˜åº¦ï¼‰
    for i in np.unique(labels):
        mask = generated_labels == i
        if np.sum(mask) > 0:
            ax2.scatter(generated_partitioned[mask, 0], generated_partitioned[mask, 1], 
                       c=colors[int(i)], 
                       marker=markers[int(i) % len(markers)],
                       alpha=0.8, s=40, 
                       label=f'Generated {names[int(i)]}')
    
    ax2.set_title('Partitioned Generation: Clear Structure', fontsize=12, fontweight='bold')
    ax2.set_xlabel('Feature X')
    ax2.set_ylabel('Feature Y')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # æ·»åŠ è¯´æ˜
    ax2.text(0.05, 0.95, "âœ… Generated data maintains\noriginal cluster structure", 
             transform=ax2.transAxes, fontsize=10, color='green',
             bbox=dict(facecolor='white', alpha=0.8))
    
    # 3. ä½ç½®åˆ†å¸ƒç»Ÿè®¡
    ax3 = plt.subplot(gs[1, 0])
    # è®¡ç®—æ¯ä¸ªåˆ†å¸ƒçš„ç´§å‡‘åº¦ï¼ˆå¹³å‡æœ€è¿‘é‚»è·ç¦»ï¼‰
    def calculate_compactness(data):
        from sklearn.neighbors import NearestNeighbors
        if len(data) < 2:
            return 0
        nbrs = NearestNeighbors(n_neighbors=2).fit(data)
        distances, _ = nbrs.kneighbors(data)
        return np.mean(distances[:, 1])
    
    compactness_global = calculate_compactness(generated_global)
    compactness_partitioned = []
    
    for i in np.unique(labels):
        mask = generated_labels == i
        if np.sum(mask) > 1:
            compactness = calculate_compactness(generated_partitioned[mask])
            compactness_partitioned.append(compactness)
    
    methods = ['Global'] + [f'Partition {i+1}' for i in range(len(compactness_partitioned))]
    compactness_values = [compactness_global] + compactness_partitioned
    
    bars = ax3.bar(methods, compactness_values, 
                   color=['red'] + colors[:len(compactness_partitioned)],
                   alpha=0.7)
    ax3.set_title('Data Compactness Comparison', fontsize=12, fontweight='bold')
    ax3.set_ylabel('Average Nearest Neighbor Distance')
    ax3.set_xlabel('Generation Method')
    ax3.tick_params(axis='x', rotation=45)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, compactness_values):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontsize=9)
    

def plot_custom_heterogeneous_data():
    """ç»˜åˆ¶è‡ªå®šä¹‰å¼‚æ„æ•°æ®å¹¶å±•ç¤ºç”Ÿæˆæ•ˆæœå¯¹æ¯”"""
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    
    # åˆ›å»ºæœ‰æ˜æ˜¾å·®å¼‚çš„åˆ†å¸ƒ
    # åˆ†å¸ƒ1: ç´§å‡‘çš„åœ†å½¢åˆ†å¸ƒ
    theta = np.random.uniform(0, 2*np.pi, 80)
    r = np.random.normal(2, 0.2, 80)
    cluster1 = np.column_stack([r * np.cos(theta) + 1, r * np.sin(theta) + 1])
    
    # åˆ†å¸ƒ2: åˆ†æ•£çš„çº¿æ€§åˆ†å¸ƒ
    x2 = np.random.uniform(-2, 4, 100)
    y2 = 0.6 * x2 + 1 + np.random.normal(0, 0.8, 100)
    cluster2 = np.column_stack([x2, y2])
    
    # åˆ†å¸ƒ3: å¦ä¸€ä¸ªç´§å‡‘åˆ†å¸ƒ
    theta3 = np.random.uniform(0, 2*np.pi, 70)
    r3 = np.random.normal(1.5, 0.25, 70)
    cluster3 = np.column_stack([r3 * np.cos(theta3) - 2, r3 * np.sin(theta3) - 1])
    
    # åˆå¹¶æ•°æ®
    X = np.vstack([cluster1, cluster2, cluster3])
    labels = np.hstack([np.zeros(80), np.ones(100), np.ones(70)*2])
    
    # å®šä¹‰é¢œè‰²å’Œåç§°
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    distribution_names = ['Distribution A', 'Distribution B', 'Distribution C']
    
    print("Generating data and comparing methods...")
    print("=" * 50)
    
    # 1. ä¸»è¦å¯¹æ¯”å›¾
    generated_global, generated_partitioned = plot_generation_comparison(X, labels, colors, distribution_names)
    
    # 2. è¯¦ç»†åˆ†æå›¾
    # plot_generation_details(X, labels, colors, distribution_names)
    
    return X, labels, generated_global, generated_partitioned

# è¿è¡Œç»˜å›¾å‡½æ•°
if __name__ == "__main__":
    print("å±•ç¤ºæ•´ä½“ç”Ÿæˆ vs åˆ’åˆ†ç”Ÿæˆçš„æ•ˆæœå¯¹æ¯”...")
    X_custom, labels_custom, global_data, partitioned_data = plot_custom_heterogeneous_data()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nåŸå§‹æ•°æ®å½¢çŠ¶: {X_custom.shape}")
    print(f"æ•´ä½“ç”Ÿæˆæ•°æ®å½¢çŠ¶: {global_data.shape}")
    print(f"åˆ’åˆ†ç”Ÿæˆæ•°æ®å½¢çŠ¶: {partitioned_data.shape}")
    print(f"åŸå§‹æ•°æ®ç±»åˆ«åˆ†å¸ƒ: {[np.sum(labels_custom == i) for i in np.unique(labels_custom)]}")